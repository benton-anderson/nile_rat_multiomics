{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f720ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from subprocess import call\n",
    "\n",
    "# from xlsx2csv import Xlsx2csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d25a7bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write an excel to csv script to file ExcelToCsv.vbs\n",
    "# https://stackoverflow.com/questions/28766133/faster-way-to-read-excel-files-to-pandas-dataframe\n",
    "# vbscript=\"\"\"if WScript.Arguments.Count < 3 Then\n",
    "#     WScript.Echo \"Please specify the source and the destination files. Usage: ExcelToCsv <xls/xlsx source file> <csv destination file> <worksheet number (starts at 1)>\"\n",
    "#     Wscript.Quit\n",
    "# End If\n",
    "\n",
    "# csv_format = 6\n",
    "\n",
    "# Set objFSO = CreateObject(\"Scripting.FileSystemObject\")\n",
    "\n",
    "# src_file = objFSO.GetAbsolutePathName(Wscript.Arguments.Item(0))\n",
    "# dest_file = objFSO.GetAbsolutePathName(WScript.Arguments.Item(1))\n",
    "# worksheet_number = CInt(WScript.Arguments.Item(2))\n",
    "\n",
    "# Dim oExcel\n",
    "# Set oExcel = CreateObject(\"Excel.Application\")\n",
    "\n",
    "# Dim oBook\n",
    "# Set oBook = oExcel.Workbooks.Open(src_file)\n",
    "# oBook.Worksheets(worksheet_number).Activate\n",
    "\n",
    "# oBook.SaveAs dest_file, csv_format\n",
    "\n",
    "# oBook.Close False\n",
    "# oExcel.Quit\n",
    "# \"\"\";\n",
    "# f = open('ExcelToCsv.vbs','w')\n",
    "# f.write(vbscript)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eda74a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel = 'Nilerat_lipids_CD33_unaligned.xlsx'\n",
    "csv = 'test.csv' \n",
    "call(['cscript.exe', 'ExcelToCsv.vbs', excel, csv, '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a199189",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('..\\\\..\\\\data\\\\search\\\\CD33\\\\')\n",
    "testfilename = Path('excel_test_file.xlsx')\n",
    "xlsxfilename = Path('Nilerat_lipids_CD33_unaligned.xlsx')\n",
    "outfile = str(path / (xlsxfilename.stem + '.csv'))\n",
    "# Xlsx2csv(str(path / xlsxfilename), \n",
    "#          skip_trailing_columns=False,\n",
    "#          outputencoding='utf-8').convert(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b36b29cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "wb = load_workbook(filename=path / xlsxfilename, read_only=True)\n",
    "ws = wb[wb.sheetnames[0]]\n",
    "\n",
    "for row in ws.rows:\n",
    "#     print(type(row))\n",
    "    pass\n",
    "#     print(row[0].value)\n",
    "#     print(row[0].value)\n",
    "    for cell in row:\n",
    "#         print(cell.value)\n",
    "        pass\n",
    "\n",
    "# Close the workbook after reading\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b10f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headers1(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Name', 'Calc. MW','RT [min]', 'Area (Max.)', 'MS2'] :\n",
    "        d[h] = line.index(h)\n",
    "    for h in line:\n",
    "        if 'Area: ' in h:\n",
    "            d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_headers2(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Calc. MW', 'RT [min]', 'FWHM [min]', 'Max. # MI', '# Adducts', \n",
    "              'Area (All Ions)', 'Study File ID']:\n",
    "        d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_headers3(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Ion', 'Charge', 'Molecular Weight', 'm/z', 'RT [min]', 'FWHM [min]', \n",
    "              '# MI', 'Area', 'Parent Area [%]', 'Study File ID']:\n",
    "        d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_unaligned_headers(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Ion', 'Charge', 'Molecular Weight', 'm/z', 'RT [min]',\n",
    "              'FWHM [min]', '# MI', 'Area', 'Parent Area [%]', 'Study File ID'] :\n",
    "        d[h] = line.index(h)\n",
    "    return d  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1010963f",
   "metadata": {},
   "source": [
    "Checked\tName\tMolecular Weight\tRT [min]\tArea (Max.)\tMS2\n",
    "\n",
    "Checked\tName\tMolecular Weight\tRT [min]\tArea (Max.)\tMS2\n",
    "\n",
    "Checked\tMolecular Weight\tRT [min]\tFWHM [min]\tMax. # MI\t# Adducts\tArea (All Ions)\tStudy File ID\n",
    "\n",
    "Checked\tMolecular Weight\tRT [min]\tFWHM [min]\tMax. # MI\t# Adducts\tArea\tStudy File ID\n",
    "\n",
    "Checked\tIon\tCharge\tMolecular Weight\tm/z\tRT [min]\tFWHM [min]\t# MI\tArea\tParent Area [%]\tStudy File ID\n",
    "\n",
    "Checked\tIon\tCharge\tMolecular Weight\tm/z\tRT [min]\tFWHM [min]\t# MI\tArea\tParent Area [%]\tStudy File ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c87d4ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from subprocess import call\n",
    "\n",
    "def get_headers1(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Name', 'Calc. MW','RT [min]', 'Area (Max.)', 'MS2'] :\n",
    "        d[h] = line.index(h)\n",
    "    for h in line:\n",
    "        if 'Area: ' in h:\n",
    "            d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_headers2(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Calc. MW', 'RT [min]', 'FWHM [min]', 'Max. # MI', '# Adducts', \n",
    "              'Area (All Ions)', 'Study File ID']:\n",
    "        d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_headers3(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Ion', 'Charge', 'Molecular Weight', 'm/z', 'RT [min]', 'FWHM [min]', \n",
    "              '# MI', 'Area', 'Parent Area [%]', 'Study File ID']:\n",
    "        d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_unaligned_headers(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Ion', 'Charge', 'Molecular Weight', 'm/z', 'RT [min]',\n",
    "              'FWHM [min]', '# MI', 'Area', 'Parent Area [%]', 'Study File ID'] :\n",
    "        d[h] = line.index(h)\n",
    "    return d  \n",
    "\n",
    "def convert_cd33(filepath, is_aligned: bool, outfilename: str=None):\n",
    "    filepath = Path(filepath)\n",
    "    if filepath.suffix == '.xlsx':\n",
    "        print('Excel file detected. Converting to .csv')\n",
    "        csv_outfile = filepath.parent / (filepath.stem + '.csv')\n",
    "        call(['cscript.exe', 'ExcelToCsv.vbs', filepath, csv_outfile, '1'])\n",
    "        filepath = csv_outfile\n",
    "    if outfilename is None:\n",
    "        outfilepath = filepath.parent / (filepath.stem + '_CD33converted' + filepath.suffix)\n",
    "    else:\n",
    "#         if '.csv' not in outfilename:\n",
    "#             outfilename += '.csv'\n",
    "        outfilepath = filepath.parent / outfilename\n",
    "    if is_aligned: \n",
    "        with open(str(filepath), encoding='utf-8') as inf:\n",
    "            with open(str(outfilepath), 'w', encoding='utf-8', newline='') as out:\n",
    "                r = csv.reader(inf)\n",
    "                w = csv.writer(out)\n",
    "                # Get indexes of headers\n",
    "                first_line = next(r)\n",
    "                h1 = get_headers1(first_line) \n",
    "                first_header = first_line[0].strip()  # e.g. \"Tags\" or \"Checked\" or whatever CD puts in 1st column\n",
    "                if type(first_header) == bytes:\n",
    "                    # Handle the utf-8 BOM (byte order mark) that arises in some CSVs\n",
    "                    first_header = first_header.decode(errors='ignore')\n",
    "                next(r)\n",
    "                second_header_line = next(r)\n",
    "                h2 = get_headers2(second_header_line)\n",
    "                second_header = second_header_line[1]\n",
    "                next(r)\n",
    "                third_header_line = next(r)\n",
    "                h3 = get_headers3(third_header_line)\n",
    "                third_header = third_header_line[2]\n",
    "#                 for line in r:\n",
    "# #                     print(type(line[1]), line[1], line[2], '\\n')\n",
    "#                     if line[1] == first_header:\n",
    "#                         print('reached h2')\n",
    "#                         h2 = get_headers2(line)\n",
    "#                     elif line[2] == first_header:\n",
    "#                         print('reached h3')\n",
    "#                         h3 = get_headers3(line)\n",
    "#                         break\n",
    "                print('first_header:', first_header, '\\nsecond_header:', second_header, '\\nthird_header:', third_header)\n",
    "                if 'RT [min]' not in h2 or 'Study File ID' not in h3:\n",
    "                    print('header2:', h2, '\\nheader3:', h3)\n",
    "                    raise ValueError('Headers not found. Do you have multiple compounds in the first 6 rows?')\n",
    "                mod_h2 = list(h2.keys())\n",
    "                for i, h in enumerate(mod_h2):\n",
    "                    if h == 'Calc. MW':\n",
    "                        mod_h2[i] = 'Molecular Weight'\n",
    "                    if h == 'Area (All Ions)':\n",
    "                        mod_h2[i] = 'Area'\n",
    "                inf.seek(0)  # Reset reader position to top of file\n",
    "                r = csv.reader(inf)  # Reset the csv reader\n",
    "                prev_line_type = None  # 'h1', 'd1', 'h2', 'd2', 'h3', 'd3'\n",
    "                for i, line in enumerate(r):\n",
    "                    \n",
    "                    # Feature data\n",
    "                    if line[1] == '' and line[2] != third_header:\n",
    "                        w.writerow(['', ''] + [line[i] for i in h3.values()] + [''])\n",
    "                    # Feature header\n",
    "                    elif line[1] == '' and line[2] == third_header:\n",
    "                        w.writerow(['', ''] + list(h3.keys()) + [''])\n",
    "                    # Compound per File data:\n",
    "                    elif line[0] == '' and line[1] != second_header:\n",
    "                        w.writerow([''] + [line[i] for i in h2.values()] + [''])\n",
    "                    # Compound per File header:\n",
    "                    elif line[0] == '' and line[1] == second_header:\n",
    "                        w.writerow([''] + mod_h2 + [''])\n",
    "                    # Compound data\n",
    "                    elif line[0] != first_header:\n",
    "                        row = [line[i] for i in h1.values()] + ['']\n",
    "                        row[list(h1.keys()).index('Name')] = ''  # Name field = Empty String because LipiDex parser doesn't like it\n",
    "                        w.writerow(row)\n",
    "                    # Compound header\n",
    "                    elif line[0] == first_header:\n",
    "                        w.writerow([('Molecular Weight' if 'Calc. MW' in key else key) for key in h1.keys()] + [''])\n",
    "                    else:\n",
    "                        raise ValueError('Could not parse line ' + str(i + 1) + ' (1-indexed)\\n' + str(line))\n",
    "#                     # Compound header\n",
    "#                     if first_header in line[0]:\n",
    "#                         w.writerow([('Molecular Weight' if 'Calc. MW' in key else key) for key in h1.keys()] + [''])\n",
    "#                         prev_line_type = 'h1'\n",
    "#                     # Compound data\n",
    "#                     elif line[0] == '' and line[1] != first_header:\n",
    "#                         row = [line[i] for i in h1.values()] + ['']\n",
    "#                         row[list(h1.keys()).index('Name')] = ''  # Name field = Empty String because LipiDex parser doesn't like it\n",
    "#                         w.writerow(row)\n",
    "#                         prev_line_type = 'd1'\n",
    "#                     # Compound per File header:\n",
    "#                     elif line[0] == '' and line[1] == first_header:\n",
    "#                         w.writerow([''] + mod_h2 + [''])\n",
    "#                     # Compound per File data:\n",
    "#                     elif line[1] == '' and line[2] != first_header:\n",
    "#                         w.writerow([''] + [line[i] for i in h2.values()] + [''])\n",
    "#                     # Feature header:\n",
    "#                     elif line[1] == '' and line[2] == first_header:\n",
    "#                         w.writerow(['', ''] + list(h3.keys()) + [''])\n",
    "#                     # Feature data:\n",
    "#                     elif line[2] == '':\n",
    "#                         w.writerow(['', ''] + [line[i] for i in h3.values()] + [''])\n",
    "                    \n",
    "    else: \n",
    "        with open(str(filepath), encoding='utf8') as inf:\n",
    "            with open(str(outfilepath), 'w', encoding='utf8', newline='') as out:\n",
    "                r = csv.reader(inf)\n",
    "                w = csv.writer(out)\n",
    "                # Get indexes of headers\n",
    "                first_line = next(r)\n",
    "                header = get_unaligned_headers(first_line) \n",
    "                w.writerow(list(header.keys()) + [''])\n",
    "                for line in r:\n",
    "                    w.writerow([line[i] for i in header.values()] + [''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f12130d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_header: ﻿Tags \n",
      "second_header: Tags \n",
      "third_header: Tags\n"
     ]
    }
   ],
   "source": [
    "aligned = r'../../data/search/CD33/Nilerat_lipids_CD33_aligned.csv'\n",
    "unaligned = r'../../data/search/CD33/Nilerat_lipids_CD33_unaligned.csv'\n",
    "\n",
    "convert_cd33(aligned, True)\n",
    "convert_cd33(unaligned, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547f32f9",
   "metadata": {},
   "source": [
    "## Unaligned file CD 3.3 converter\n",
    "\n",
    "Checked\tIon\tCharge\tMolecular Weight\tm/z\tRT [min]\tFWHM [min]\t# MI\tArea\tParent Area [%]\tStudy File ID\n",
    "\n",
    "\n",
    "Checked\tIon\tCharge\tMolecular Weight\tm/z\tRT [min]\tFWHM [min]\t# MI\tArea\tParent Area [%]\tStudy File ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47b60dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unaligned_headers(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Ion', 'Charge', 'Molecular Weight', 'm/z', 'RT [min]',\n",
    "              'FWHM [min]', '# MI', 'Area', 'Parent Area [%]', 'Study File ID'] :\n",
    "        d[h] = line.index(h)\n",
    "    return d  \n",
    "\n",
    "with open(r'../data/search/CD33/Nilerat_lipids_CD33_unaligned.csv', encoding='utf8') as inf:\n",
    "    with open(r'..\\data\\search\\CD33\\unaligned_test.csv', 'w', encoding='utf8', newline='') as out:\n",
    "        r = csv.reader(inf)\n",
    "        w = csv.writer(out)\n",
    "        # Get indexes of headers\n",
    "        first_line = next(r)\n",
    "        header = get_unaligned_headers(first_line) \n",
    "        w.writerow(list(header.keys()))\n",
    "        for line in r:\n",
    "            w.writerow([line[i] for i in header.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "87124628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-o', '--outfilename'], dest='outfilename', nargs=None, const=None, default=None, type=None, choices=None, help='(Optional) Filename for converted file', metavar=None)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-f', '--file', dest='filepath', type=str, \n",
    "                    help='CD 3.3 .csv file to convert')\n",
    "aligned_flag = parser.add_mutually_exclusive_group()\n",
    "aligned_flag.add_argument('-a', '--aligned', dest='is_aligned', action='store_true')\n",
    "aligned_flag.add_argument('-u', '--unaligned', dest='is_aligned', action='store_false')\n",
    "parser.add_argument('-o', '--outfilename', dest='outfilename', default=None,\n",
    "                    help='(Optional) Filename for converted file')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "706bab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(['-f', 'asdf', '--aligned',])\n",
    "print(args.outfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "722305ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\bjanderson23\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-d53dbdbd-323b-49a9-bb24-030dd55a26f3.json'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse_args().filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ac457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe44efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440622a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c0fb22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda9ba6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0889a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960515c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df80eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a96493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611b4cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
