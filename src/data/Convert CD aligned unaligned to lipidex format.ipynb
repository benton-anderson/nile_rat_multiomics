{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f720ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from subprocess import call\n",
    "\n",
    "# from xlsx2csv import Xlsx2csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d25a7bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write an excel to csv script to file ExcelToCsv.vbs\n",
    "# https://stackoverflow.com/questions/28766133/faster-way-to-read-excel-files-to-pandas-dataframe\n",
    "# vbscript=\"\"\"if WScript.Arguments.Count < 3 Then\n",
    "#     WScript.Echo \"Please specify the source and the destination files. Usage: ExcelToCsv <xls/xlsx source file> <csv destination file> <worksheet number (starts at 1)>\"\n",
    "#     Wscript.Quit\n",
    "# End If\n",
    "\n",
    "# csv_format = 6\n",
    "\n",
    "# Set objFSO = CreateObject(\"Scripting.FileSystemObject\")\n",
    "\n",
    "# src_file = objFSO.GetAbsolutePathName(Wscript.Arguments.Item(0))\n",
    "# dest_file = objFSO.GetAbsolutePathName(WScript.Arguments.Item(1))\n",
    "# worksheet_number = CInt(WScript.Arguments.Item(2))\n",
    "\n",
    "# Dim oExcel\n",
    "# Set oExcel = CreateObject(\"Excel.Application\")\n",
    "\n",
    "# Dim oBook\n",
    "# Set oBook = oExcel.Workbooks.Open(src_file)\n",
    "# oBook.Worksheets(worksheet_number).Activate\n",
    "\n",
    "# oBook.SaveAs dest_file, csv_format\n",
    "\n",
    "# oBook.Close False\n",
    "# oExcel.Quit\n",
    "# \"\"\";\n",
    "# f = open('ExcelToCsv.vbs','w')\n",
    "# f.write(vbscript)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eda74a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel = 'Nilerat_lipids_CD33_unaligned.xlsx'\n",
    "csv = 'test.csv' \n",
    "call(['cscript.exe', 'ExcelToCsv.vbs', excel, csv, '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a199189",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('..\\\\..\\\\data\\\\search\\\\CD33\\\\')\n",
    "testfilename = Path('excel_test_file.xlsx')\n",
    "xlsxfilename = Path('Nilerat_lipids_CD33_unaligned.xlsx')\n",
    "outfile = str(path / (xlsxfilename.stem + '.csv'))\n",
    "# Xlsx2csv(str(path / xlsxfilename), \n",
    "#          skip_trailing_columns=False,\n",
    "#          outputencoding='utf-8').convert(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b36b29cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "wb = load_workbook(filename=path / xlsxfilename, read_only=True)\n",
    "ws = wb[wb.sheetnames[0]]\n",
    "\n",
    "for row in ws.rows:\n",
    "#     print(type(row))\n",
    "    pass\n",
    "#     print(row[0].value)\n",
    "#     print(row[0].value)\n",
    "    for cell in row:\n",
    "#         print(cell.value)\n",
    "        pass\n",
    "\n",
    "# Close the workbook after reading\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b10f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headers1(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Name', 'Calc. MW','RT [min]', 'Area (Max.)', 'MS2'] :\n",
    "        d[h] = line.index(h)\n",
    "    for h in line:\n",
    "        if 'Area: ' in h:\n",
    "            d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_headers2(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Calc. MW', 'RT [min]', 'FWHM [min]', 'Max. # MI', '# Adducts', \n",
    "              'Area (All Ions)', 'Study File ID']:\n",
    "        d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_headers3(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Ion', 'Charge', 'Molecular Weight', 'm/z', 'RT [min]', 'FWHM [min]', \n",
    "              '# MI', 'Area', 'Parent Area [%]', 'Study File ID']:\n",
    "        d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_unaligned_headers(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Ion', 'Charge', 'Molecular Weight', 'm/z', 'RT [min]',\n",
    "              'FWHM [min]', '# MI', 'Area', 'Parent Area [%]', 'Study File ID'] :\n",
    "        d[h] = line.index(h)\n",
    "    return d  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1010963f",
   "metadata": {},
   "source": [
    "Checked\tName\tMolecular Weight\tRT [min]\tArea (Max.)\tMS2\n",
    "\n",
    "Checked\tName\tMolecular Weight\tRT [min]\tArea (Max.)\tMS2\n",
    "\n",
    "Checked\tMolecular Weight\tRT [min]\tFWHM [min]\tMax. # MI\t# Adducts\tArea (All Ions)\tStudy File ID\n",
    "\n",
    "Checked\tMolecular Weight\tRT [min]\tFWHM [min]\tMax. # MI\t# Adducts\tArea\tStudy File ID\n",
    "\n",
    "Checked\tIon\tCharge\tMolecular Weight\tm/z\tRT [min]\tFWHM [min]\t# MI\tArea\tParent Area [%]\tStudy File ID\n",
    "\n",
    "Checked\tIon\tCharge\tMolecular Weight\tm/z\tRT [min]\tFWHM [min]\t# MI\tArea\tParent Area [%]\tStudy File ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a8ed2023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['asdf', 'a'].index('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0f3885c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c87d4ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from subprocess import call\n",
    "from collections import OrderedDict\n",
    "\n",
    "def get_headers1(line):\n",
    "    d = OrderedDict()\n",
    "    for h in ['Checked', 'Name', 'Calc. MW','RT [min]', 'Area (Max.)', 'MS2'] :\n",
    "        d[h] = line.index(h)\n",
    "    area_counter = 0\n",
    "    for h in line:\n",
    "        if 'Area: ' in h:\n",
    "            d[h] = line.index(h)\n",
    "            area_counter += 1\n",
    "    if area_counter == 0:\n",
    "        raise ValueError('Area per file data is missing from file. Re-do CD export with Area data.')\n",
    "    return d\n",
    "\n",
    "def get_headers2(line):\n",
    "    d = OrderedDict()\n",
    "    for h in ['Checked', 'Calc. MW', 'RT [min]', 'FWHM [min]', 'Max. # MI', '# Adducts', \n",
    "              'Area (All Ions)', 'Study File ID']:\n",
    "        d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_headers3(line):\n",
    "    d = OrderedDict()\n",
    "    for h in ['Checked', 'Ion', 'Charge', 'Molecular Weight', 'm/z', 'RT [min]', 'FWHM [min]', \n",
    "              '# MI', 'Area', 'Parent Area [%]', 'Study File ID']:\n",
    "        d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_unaligned_headers(line):\n",
    "    d = OrderedDict()\n",
    "    for h in ['Checked', 'Ion', 'Charge', 'Molecular Weight', 'm/z', 'RT [min]',\n",
    "              'FWHM [min]', '# MI', 'Area', 'Parent Area [%]', 'Study File ID'] :\n",
    "        d[h] = line.index(h)\n",
    "    return d  \n",
    "\n",
    "def convert_excel_to_csv(xlsx_filepath, csv_filepath, script_location='default'):\n",
    "    pass\n",
    "\n",
    "def convert_cd33(filepath, is_aligned: bool, outfilename: str=None):\n",
    "    filepath = Path(filepath)\n",
    "    if filepath.suffix == '.xlsx':\n",
    "        print('Excel file detected. Converting to .csv')\n",
    "        csv_outfile = filepath.parent / (filepath.stem + '.csv')\n",
    "        call(['cscript.exe', 'ExcelToCsv.vbs', str(filepath), str(csv_outfile), '1'])\n",
    "        filepath = csv_outfile\n",
    "    if outfilename is None:\n",
    "        outfilepath = filepath.parent / (filepath.stem + '_CD33converted' + filepath.suffix)\n",
    "    else:\n",
    "#         if '.csv' not in outfilename:\n",
    "#             outfilename += '.csv'\n",
    "        outfilepath = filepath.parent / outfilename\n",
    "    if is_aligned: \n",
    "        with open(str(filepath), encoding='utf-8-sig', mode='r', errors='ignore') as inf:\n",
    "            with open(str(outfilepath), 'w', encoding='utf-8', newline='') as out:\n",
    "                r = csv.reader(inf)\n",
    "                w = csv.writer(out)\n",
    "                # Get indexes of headers\n",
    "                first_line = next(r)\n",
    "                h1 = get_headers1(first_line) \n",
    "                first_header = first_line[0].strip()  # e.g. \"Tags\" or \"Checked\" or whatever CD puts in 1st column\n",
    "                if type(first_header) == bytes:\n",
    "                    # Handle the utf-8 BOM (byte order mark) that arises in some CSVs\n",
    "                    first_header = first_header.decode(errors='ignore')\n",
    "                next(r)\n",
    "                second_header_line = next(r)\n",
    "                h2 = get_headers2(second_header_line)\n",
    "                second_header = second_header_line[1]\n",
    "                next(r)\n",
    "                third_header_line = next(r)\n",
    "                h3 = get_headers3(third_header_line)\n",
    "                third_header = third_header_line[2]\n",
    "#                 for line in r:\n",
    "# #                     print(type(line[1]), line[1], line[2], '\\n')\n",
    "#                     if line[1] == first_header:\n",
    "#                         print('reached h2')\n",
    "#                         h2 = get_headers2(line)\n",
    "#                     elif line[2] == first_header:\n",
    "#                         print('reached h3')\n",
    "#                         h3 = get_headers3(line)\n",
    "#                         break\n",
    "                print('first_header:', first_header, '\\nsecond_header:', second_header, '\\nthird_header:', third_header)\n",
    "                if 'RT [min]' not in h2 or 'Study File ID' not in h3:\n",
    "                    print('header2:', h2, '\\nheader3:', h3)\n",
    "                    raise ValueError('Headers not found. Do you have multiple Compound Groups or'\n",
    "                                     ' Compounds per File in the first 6 rows?')\n",
    "                mod_h2 = list(h2.keys())\n",
    "                for i, h in enumerate(mod_h2):\n",
    "                    if h == 'Calc. MW':\n",
    "                        mod_h2[i] = 'Molecular Weight'\n",
    "                    if h == 'Area (All Ions)':\n",
    "                        mod_h2[i] = 'Area'\n",
    "                inf.seek(0)  # Reset reader position to top of file\n",
    "                r = csv.reader(inf)  # Reset the csv reader\n",
    "                prev_line_type = None  # 'h1', 'd1', 'h2', 'd2', 'h3', 'd3'\n",
    "                for i, line in enumerate(r):\n",
    "                    \n",
    "                    # Feature data\n",
    "                    if line[1] == '' and line[2] != third_header:\n",
    "                        w.writerow(['', ''] + [line[i] for i in h3.values()] + [''])\n",
    "                    # Feature header\n",
    "                    elif line[1] == '' and line[2] == third_header:\n",
    "                        w.writerow(['', ''] + list(h3.keys()) + [''])\n",
    "                    # Compound per File data:\n",
    "                    elif line[0] == '' and line[1] != second_header:\n",
    "                        w.writerow([''] + [line[i] for i in h2.values()] + [''])\n",
    "                    # Compound per File header:\n",
    "                    elif line[0] == '' and line[1] == second_header:\n",
    "                        w.writerow([''] + mod_h2 + [''])\n",
    "                    # Compound data\n",
    "                    elif line[0] != first_header:\n",
    "                        row = [line[i] for i in h1.values()] + ['']\n",
    "                        row[list(h1.keys()).index('Name')] = ''  # Name field = Empty String because LipiDex parser doesn't like it\n",
    "                        w.writerow(row)\n",
    "                    # Compound header\n",
    "                    elif line[0] == first_header:\n",
    "                        w.writerow([('Molecular Weight' if 'Calc. MW' in key else key) for key in h1.keys()] + [''])\n",
    "                    else:\n",
    "                        raise ValueError('Could not parse line ' + str(i + 1) + ' (1-indexed)\\n' + str(line))\n",
    "#                     # Compound header\n",
    "#                     if first_header in line[0]:\n",
    "#                         w.writerow([('Molecular Weight' if 'Calc. MW' in key else key) for key in h1.keys()] + [''])\n",
    "#                         prev_line_type = 'h1'\n",
    "#                     # Compound data\n",
    "#                     elif line[0] == '' and line[1] != first_header:\n",
    "#                         row = [line[i] for i in h1.values()] + ['']\n",
    "#                         row[list(h1.keys()).index('Name')] = ''  # Name field = Empty String because LipiDex parser doesn't like it\n",
    "#                         w.writerow(row)\n",
    "#                         prev_line_type = 'd1'\n",
    "#                     # Compound per File header:\n",
    "#                     elif line[0] == '' and line[1] == first_header:\n",
    "#                         w.writerow([''] + mod_h2 + [''])\n",
    "#                     # Compound per File data:\n",
    "#                     elif line[1] == '' and line[2] != first_header:\n",
    "#                         w.writerow([''] + [line[i] for i in h2.values()] + [''])\n",
    "#                     # Feature header:\n",
    "#                     elif line[1] == '' and line[2] == first_header:\n",
    "#                         w.writerow(['', ''] + list(h3.keys()) + [''])\n",
    "#                     # Feature data:\n",
    "#                     elif line[2] == '':\n",
    "#                         w.writerow(['', ''] + [line[i] for i in h3.values()] + [''])\n",
    "                    \n",
    "    else: \n",
    "        with open(str(filepath), encoding='utf8') as inf:\n",
    "            with open(str(outfilepath), 'w', encoding='utf8', newline='') as out:\n",
    "                r = csv.reader(inf)\n",
    "                w = csv.writer(out)\n",
    "                # Get indexes of headers\n",
    "                first_line = next(r)\n",
    "                header = get_unaligned_headers(first_line) \n",
    "                w.writerow(list(header.keys()) + [''])\n",
    "                for line in r:\n",
    "                    w.writerow([line[i] for i in header.values()] + [''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f65c6ca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Checked'\n",
      "Checked\n",
      "{'Checked': 0, 'Name': 1, 'Calc. MW': 8, 'RT [min]': 10, 'Area (Max.)': 11, 'MS2': 16, 'Area: 20210729_AJ_Toh_RatBloodGlucose_ExtractionBlank.raw (F1)': 487, 'Area: 20210729_AJ_Toh_RatBloodGlucose_SolventBlank.raw (F2)': 488, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1060M_20210322_8wk_FBG.raw (F3)': 489, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1060M_20210325_8wk_RBG.raw (F4)': 490, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1060M_20210329_9wk_FBG.raw (F5)': 491, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1060M_20210401_9wk_RBG.raw (F6)': 492, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1060M_20210405_10wk_FBG.raw (F7)': 493, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1060M_20210408_10wk_RBG.raw (F8)': 494, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1062M_20210322_8wk_FBG.raw (F9)': 495, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1062M_20210325_8wk_RBG.raw (F10)': 496, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1062M_20210329_9wk_FBG_QC1.raw (F11)': 497, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1062M_20210329_9wk_FBG_QC2.raw (F12)': 498, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1062M_20210329_9wk_FBG_QC3.raw (F13)': 499, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1062M_20210401_9wk_RBG.raw (F14)': 500, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1062M_20210405_10wk_FBG.raw (F15)': 501, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1062M_20210408_10wk_RBG.raw (F16)': 502, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1074M_20210322_8wk_FBG.raw (F17)': 503, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1074M_20210325_8wk_RBG.raw (F18)': 504, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1074M_20210329_9wk_FBG.raw (F19)': 505, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1074M_20210401_9wk_RBG.raw (F20)': 506, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1074M_20210405_10wk_FBG.raw (F21)': 507, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1074M_20210408_10wk_RBG.raw (F22)': 508, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1076M_20210322_8wk_FBG.raw (F23)': 509, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1076M_20210325_8wk_RBG.raw (F24)': 510, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1076M_20210329_9wk_FBG.raw (F25)': 511, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1076M_20210401_9wk_RBG.raw (F26)': 512, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1076M_20210405_10wk_FBG.raw (F27)': 513, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1076M_20210408_10wk_RBG.raw (F28)': 514, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1082M_20210322_8wk_FBG.raw (F29)': 515, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1082M_20210325_8wk_RBG.raw (F30)': 516, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1082M_20210329_9wk_FBG.raw (F31)': 517, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1082M_20210401_9wk_RBG.raw (F32)': 518, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1082M_20210405_10wk_FBG.raw (F33)': 519, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1082M_20210408_10wk_RBG.raw (F34)': 520, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1091M_20210327_8wk_FBG.raw (F35)': 521, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1091M_20210330_8wk_RBG.raw (F36)': 522, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1091M_20210402_9wk_FBG.raw (F37)': 523, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1091M_20210406_9wk_RBG.raw (F38)': 524, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1091M_20210410_10wk_FBG.raw (F39)': 525, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1091M_20210413_10wk_RBG.raw (F40)': 526, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1092M_20210327_8wk_FBG.raw (F41)': 527, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1092M_20210330_8wk_RBG.raw (F42)': 528, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1092M_20210402_9wk_FBG.raw (F43)': 529, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1092M_20210406_9wk_RBG.raw (F44)': 530, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1092M_20210410_10wk_FBG.raw (F45)': 531, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1092M_20210413_10wk_RBG.raw (F46)': 532, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1093M_20210327_8wk_FBG.raw (F47)': 533, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1093M_20210330_8wk_RBG.raw (F48)': 534, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1093M_20210402_9wk_FBG.raw (F49)': 535, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1093M_20210406_9wk_RBG.raw (F50)': 536, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1093M_20210410_10wk_FBG.raw (F51)': 537, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1093M_20210413_10wk_RBG.raw (F52)': 538, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1101M_20210327_8wk_FBG.raw (F53)': 539, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1101M_20210330_8wk_RBG.raw (F54)': 540, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1101M_20210402_9wk_FBG.raw (F55)': 541, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1101M_20210406_9wk_RBG.raw (F56)': 542, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1101M_20210410_10wk_FBG.raw (F57)': 543, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1101M_20210413_10wk_RBG.raw (F58)': 544, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1102M_20210327_8wk_FBG.raw (F59)': 545, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1102M_20210330_8wk_RBG.raw (F60)': 546, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1102M_20210402_9wk_FBG.raw (F61)': 547, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1102M_20210406_9wk_RBG.raw (F62)': 548, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1102M_20210410_10wk_FBG.raw (F63)': 549, 'Area: 20210729_AJ_Toh_RatBloodGlucose_T1102M_20210413_10wk_RBG.raw (F64)': 550, 'Area: 20210729_AJ_Toh_RatBloodGlucose_Water_R1.raw (F65)': 551, 'Area: 20210729_AJ_Toh_RatBloodGlucose_Water_R2.raw (F66)': 552, 'Area: 20210729_AJ_Toh_RatBloodGlucose_Water_R3.raw (F67)': 553}\n",
      "['FALSE', '1-Linoleoyl-2-Hydroxy-sn-glycero-3-PC', 'C26 H50 N O7 P', 'Full match', 'No results', 'No results', 'Full match', '0.88', '519.33295', '520.34011', '1.062', '929261128.7', '0', '', '', '', 'DDA for preferred ion', '[M+H]+1', '', '', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '', '', '', '', '', '10', '10', '10', '10', '8.9', '10', '10', '7.8', '9.5', '9.5', '', '9.5', '10', '10', '9.5', '10', '10', '9.5', '10', '9.5', '7.3', '10', '10', '10', '8.9', '10', '10', '10', '9.5', '10', '8.9', '10', '10', '10', '10', '10', '10', '9.5', '7.8', '9.5', '9.5', '9.5', '7.3', '10', '7.8', '9.5', '10', '8.9', '10', '8.9', '10', '10', '10', '9.5', '10', '10', '9.5', '10', '10', '10', '8.9', '9.5', '', '', '', '', '', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '', '', '', '', '', '0.16', '0.16', '0.16', '0.14', '0.32', '0.16', '0.16', '0.34', '0.16', '0.2', '', '0.24', '0.17', '0.16', '0.22', '0.15', '0.17', '0.2', '0.16', '0.21', '0.19', '0.18', '0.16', '0.12', '0.1', '0.16', '0.19', '0.16', '0.15', '0.16', '0.28', '0.16', '0.16', '0.16', '0.16', '0.11', '0.16', '0.2', '0.12', '0.19', '0.17', '0.13', '0.15', '0.16', '0.17', '0.25', '0.11', '0.21', '0.18', '0.27', '0.18', '0.09', '0.16', '0.22', '0.15', '0.17', '0.13', '0.16', '0.16', '0.16', '0.16', '0.18', '', '', '', '', '', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '', '', '', '8', '32', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '8', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '32', '32', '32', 'Full gap', 'Full gap', 'Missing ions', 'Missing ions', 'Missing ions', 'No gap', 'No gap', 'Missing ions', 'No gap', 'Missing ions', 'Missing ions', 'No gap', 'Full gap', 'Missing ions', 'Missing ions', 'Missing ions', 'Missing ions', 'No gap', 'Missing ions', 'Missing ions', 'Missing ions', 'No gap', 'No gap', 'Missing ions', 'Missing ions', 'No gap', 'Missing ions', 'Missing ions', 'No gap', 'Missing ions', 'No gap', 'Missing ions', 'No gap', 'Missing ions', 'Missing ions', 'No gap', 'No gap', 'Missing ions', 'Missing ions', 'Missing ions', 'Missing ions', 'No gap', 'Missing ions', 'Missing ions', 'Missing ions', 'Missing ions', 'No gap', 'Missing ions', 'Missing ions', 'No gap', 'No gap', 'No gap', 'No gap', 'Missing ions', 'Missing ions', 'No gap', 'Missing ions', 'Missing ions', 'Missing ions', 'Missing ions', 'Missing ions', 'Missing ions', 'Missing ions', 'No gap', 'Full gap', 'Full gap', 'Full gap', '39126.07781', '2368.293204', '40059101.73', '408981282.3', '132501882.1', '583538312.8', '93469784.43', '499180207.1', '98227073.68', '308149857.1', '69446796.89', '159941546.3', '97851212.91', '668991216.7', '78008512.12', '420312094.9', '198403467', '929261128.7', '46743123.8', '413031293.3', '191691811.2', '303790342.1', '194574202.6', '497567904', '255869859.8', '312115625', '111420042.5', '313012428.2', '146540187.3', '229895891.9', '172415194.1', '281237914', '126151017.1', '339910783.8', '170163846.9', '412737663.2', '497831930', '383200696.9', '182643490.2', '384128340.5', '211919268.4', '503833621.8', '82576351.91', '313584303.6', '256392047.4', '136974251.4', '331816888.5', '112068618.2', '156673498.2', '562672456.7', '349842887.1', '306294615', '120952701.4', '381913343.6', '193848065', '336154354.5', '141453133', '459343257', '196496635', '181960618.4', '219078065.6', '532540099.3', '174510207.3', '245809217.8', '2759.597462', '2448.56601', '2407.799454']\n"
     ]
    }
   ],
   "source": [
    "with open(r'../../data/search/CD33/CD_output/test_files/parsing_test.csv', encoding='utf-8-sig', mode='r') as infile:\n",
    "    r = csv.reader(infile)\n",
    "    \n",
    "    first_header_line = next(r)\n",
    "    first_header = first_header_line[0].strip()  # e.g. \"Tags\" or \"Checked\" or whatever CD puts in 1st column\n",
    "    print(first_header.encode())\n",
    "    if type(first_header) == bytes:\n",
    "        # Handle the utf-8 BOM (byte order mark) that arises in some CSVs\n",
    "        first_header = first_header.decode(errors='ignore')\n",
    "    print(first_header)\n",
    "    \n",
    "    h1 = get_headers1(first_header_line)\n",
    "    print(dict(h1))\n",
    "    \n",
    "    first_data_line = next(r)\n",
    "    print(first_data_line)\n",
    "    \n",
    "#     for line in r:\n",
    "#         print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f12130d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_header: ï»¿Tags \n",
      "second_header: Tags \n",
      "third_header: Tags\n"
     ]
    }
   ],
   "source": [
    "aligned = r'../../data/search/CD33/CD_output/Nilerat_lipids_CD33_aligned.csv'\n",
    "unaligned = r'../../data/search/CD33/CD_output/Nilerat_lipids_CD33_unaligned.csv'\n",
    "\n",
    "convert_cd33(aligned, True)\n",
    "# convert_cd33(unaligned, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "07ae1463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_header: Tags \n",
      "second_header: Tags \n",
      "third_header: Tags\n"
     ]
    }
   ],
   "source": [
    "fp = r'../../data/search/CD33/CD_output/Nilerat_lipids_CD33_aligned_filtered_20220331.csv'\n",
    "convert_cd33(fp, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2802b898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = r'../../data/search/CD33/CD_output/Nilerat_lipids_CD33_aligned_filtered_20220331.xlsx'\n",
    "csv_outfile = '../../data/search/CD33/CD_output/Nilerat_lipids_CD33_aligned_filtered_20220331.csv'\n",
    "\n",
    "call(['cscript.exe', 'ExcelToCsv.vbs', fp, csv_outfile, '1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547f32f9",
   "metadata": {},
   "source": [
    "## Unaligned file CD 3.3 converter\n",
    "\n",
    "Checked\tIon\tCharge\tMolecular Weight\tm/z\tRT [min]\tFWHM [min]\t# MI\tArea\tParent Area [%]\tStudy File ID\n",
    "\n",
    "\n",
    "Checked\tIon\tCharge\tMolecular Weight\tm/z\tRT [min]\tFWHM [min]\t# MI\tArea\tParent Area [%]\tStudy File ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47b60dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unaligned_headers(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Ion', 'Charge', 'Molecular Weight', 'm/z', 'RT [min]',\n",
    "              'FWHM [min]', '# MI', 'Area', 'Parent Area [%]', 'Study File ID'] :\n",
    "        d[h] = line.index(h)\n",
    "    return d  \n",
    "\n",
    "with open(r'../data/search/CD33/Nilerat_lipids_CD33_unaligned.csv', encoding='utf8') as inf:\n",
    "    with open(r'..\\data\\search\\CD33\\unaligned_test.csv', 'w', encoding='utf8', newline='') as out:\n",
    "        r = csv.reader(inf)\n",
    "        w = csv.writer(out)\n",
    "        # Get indexes of headers\n",
    "        first_line = next(r)\n",
    "        header = get_unaligned_headers(first_line) \n",
    "        w.writerow(list(header.keys()))\n",
    "        for line in r:\n",
    "            w.writerow([line[i] for i in header.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "87124628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-o', '--outfilename'], dest='outfilename', nargs=None, const=None, default=None, type=None, choices=None, help='(Optional) Filename for converted file', metavar=None)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-f', '--file', dest='filepath', type=str, \n",
    "                    help='CD 3.3 .csv file to convert')\n",
    "aligned_flag = parser.add_mutually_exclusive_group()\n",
    "aligned_flag.add_argument('-a', '--aligned', dest='is_aligned', action='store_true')\n",
    "aligned_flag.add_argument('-u', '--unaligned', dest='is_aligned', action='store_false')\n",
    "parser.add_argument('-o', '--outfilename', dest='outfilename', default=None,\n",
    "                    help='(Optional) Filename for converted file')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "706bab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(['-f', 'asdf', '--aligned',])\n",
    "print(args.outfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "722305ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\bjanderson23\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-d53dbdbd-323b-49a9-bb24-030dd55a26f3.json'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse_args().filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ac457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe44efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440622a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c0fb22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "dda9ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "def get_headers1(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Name', 'Calc. MW','RT [min]', 'Area (Max.)', 'MS2'] :\n",
    "        d[h] = line.index(h)\n",
    "    for h in line:\n",
    "        if 'Area: ' in h:\n",
    "            d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_headers2(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Calc. MW', 'RT [min]', 'FWHM [min]', 'Max. # MI', '# Adducts', \n",
    "              'Area (All Ions)', 'Study File ID']:\n",
    "        d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_headers3(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Ion', 'Charge', 'Molecular Weight', 'm/z', 'RT [min]', 'FWHM [min]', \n",
    "              '# MI', 'Area', 'Parent Area [%]', 'Study File ID']:\n",
    "        d[h] = line.index(h)\n",
    "    return d\n",
    "\n",
    "def get_unaligned_headers(line):\n",
    "    d = {}\n",
    "    for h in ['Checked', 'Ion', 'Charge', 'Molecular Weight', 'm/z', 'RT [min]',\n",
    "              'FWHM [min]', '# MI', 'Area', 'Parent Area [%]', 'Study File ID'] :\n",
    "        d[h] = line.index(h)\n",
    "    return d  \n",
    "\n",
    "def convert_cd33(filepath, is_aligned: bool, outfilename: str=None):\n",
    "    filepath = Path(filepath)\n",
    "    if outfilename is None:\n",
    "        outfilepath = filepath.parent / (filepath.stem + '_CD33converted' + filepath.suffix)\n",
    "    else:\n",
    "        if '.csv' not in outfilename:\n",
    "            outfilename += '.csv'\n",
    "        outfilepath = filepath.parent / outfilename\n",
    "    if is_aligned: \n",
    "        with open(str(filepath), encoding='utf8', errors='ignore') as inf:\n",
    "            with open(str(outfilepath), 'w', encoding='utf8', newline='') as out:\n",
    "                r = csv.reader(inf)\n",
    "                w = csv.writer(out)\n",
    "                # Get indexes of headers\n",
    "                first_line = next(r)\n",
    "                h1 = get_headers1(first_line) \n",
    "                # Get headers2 and headers3\n",
    "                for line in r:\n",
    "                    if line[0] == '' and line[1] == 'Tags':\n",
    "                        h2 = get_headers2(line)\n",
    "                    if line[1] == '' and line[2] == 'Tags':\n",
    "                        h3 = get_headers3(line)\n",
    "                        break\n",
    "                mod_h2 = list(h2.keys())\n",
    "                for i, h in enumerate(mod_h2):\n",
    "                    if h == 'Calc. MW':\n",
    "                        mod_h2[i] = 'Molecular Weight'\n",
    "                    if h == 'Area (All Ions)':\n",
    "                        mod_h2[i] = 'Area'\n",
    "                inf.seek(0)  # Reset reader position to top of file\n",
    "                r = csv.reader(inf)  # Reset the csv reader\n",
    "                for i, line in enumerate(r):\n",
    "                    # Compound header\n",
    "                    if 'Tags' in line[0]:\n",
    "                        w.writerow([('Molecular Weight' if 'Calc. MW' in key else key) for key in h1.keys()] + [''])\n",
    "                    # Compound data\n",
    "                    elif line[0] == '' and line[1] == 'FALSE':\n",
    "                        row = [line[i] for i in h1.values()] + ['']\n",
    "                        row[list(h1.keys()).index('Name')] = ''  # Name field = Empty String because LipiDex parser doesn't like it\n",
    "                        w.writerow(row)\n",
    "                    # Compound per File header:\n",
    "                    elif line[0] == '' and line[1] == 'Tags':\n",
    "                        w.writerow([''] + mod_h2 + [''])\n",
    "                    # Compound per File data:\n",
    "                    elif line[1] == '' and line[2] == 'FALSE':\n",
    "                        w.writerow([''] + [line[i] for i in h2.values()] + [''])\n",
    "                    # Feature header:\n",
    "                    elif line[1] == '' and line[2] == 'Tags':\n",
    "                        w.writerow(['', ''] + list(h3.keys()) + [''])\n",
    "                    # Feature data:\n",
    "                    elif line[2] == '':\n",
    "                        w.writerow(['', ''] + [line[i] for i in h3.values()] + [''])\n",
    "                    else:\n",
    "                        raise ValueError('line ' + str(i) + ' was not written\\n' + str(line))\n",
    "    else: \n",
    "        with open(str(filepath), encoding='utf8') as inf:\n",
    "            with open(str(outfilepath), 'w', encoding='utf8', newline='') as out:\n",
    "                r = csv.reader(inf)\n",
    "                w = csv.writer(out)\n",
    "                # Get indexes of headers\n",
    "                first_line = next(r)\n",
    "                header = get_unaligned_headers(first_line) \n",
    "                w.writerow(list(header.keys()) + [''])\n",
    "                for line in r:\n",
    "                    w.writerow([line[i] for i in header.values()] + [''])\n",
    "        \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "# \tif sys.version_info[0] < 3 or sys.version_info[1] < 7:\n",
    "# \t\traise Exception('Must use Python version 3.7 or higher')\n",
    "# \tparser = argparse.ArgumentParser()\n",
    "# \tparser.add_argument('-f', '--file', dest='filepath', type=str, \n",
    "# \t\t\t\t\t\thelp='CD 3.3 .csv file to convert')\n",
    "# \taligned_flag = parser.add_mutually_exclusive_group()\n",
    "# \taligned_flag.add_argument('-a', '--aligned', dest='is_aligned', action='store_true')\n",
    "# \taligned_flag.add_argument('-u', '--unaligned', dest='is_aligned', action='store_false')\n",
    "# \tparser.add_argument('-o', '--outfilename', dest='outfilename',\n",
    "# \t\t\t\t\t\thelp='(Optional) Filename for converted file')\n",
    "# \targs = parser.parse_args(sys.argv[1:])\n",
    "\t\n",
    "# \tconvert_cd33(\n",
    "# \t\tfilepath=args.filepath, \n",
    "# \t\tis_aligned=args.is_aligned, \n",
    "# \t\toutfilename=args.outfilename)\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "37457b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = r'../../data/search/CD33/CD_output/Nilerat_lipids_CD33_aligned_filtered_20220331.xlsx'\n",
    "csv_outfile = '../../data/search/CD33/CD_output/Nilerat_lipids_CD33_aligned_filtered_20220331.csv'\n",
    "\n",
    "call(['cscript.exe', 'ExcelToCsv.vbs', fp, csv_outfile, '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d0889a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_cd33(filepath=r'../../data/search/CD33/CD_output/Nilerat_lipids_CD33_aligned_filtered_20220331.csv', \n",
    "             is_aligned=True, \n",
    "             outfilename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960515c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df80eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a96493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611b4cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
